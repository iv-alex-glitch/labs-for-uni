{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iv-alex-glitch/labs-for-uni/blob/main/human-machine-interactionlab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILGi0qsSyXPP"
      },
      "source": [
        "# Лабораторна робота №2\n",
        "## Наївний баєсів класифікатор + SentiWordNet\n",
        "---\n",
        "Цей ноутбук використовує Naive Bayes та словник SentiWordNet для аналізу тональності."
      ],
      "id": "ILGi0qsSyXPP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W-8wYQWyXPb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import twitter_samples, stopwords, sentiwordnet as swn\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('sentiwordnet')"
      ],
      "id": "3W-8wYQWyXPb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7PvvtSPyXPf"
      },
      "outputs": [],
      "source": [
        "def process_tweet(tweet):\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    clean = []\n",
        "    for word in tokens:\n",
        "        if word not in stopwords_english and word not in string.punctuation:\n",
        "            clean.append(stemmer.stem(word))\n",
        "    return clean"
      ],
      "id": "F7PvvtSPyXPf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNOxaIUdyXPh"
      },
      "outputs": [],
      "source": [
        "all_pos = twitter_samples.strings('positive_tweets.json')\n",
        "all_neg = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "train_pos = all_pos[:4000]\n",
        "test_pos  = all_pos[4000:]\n",
        "train_neg = all_neg[:4000]\n",
        "test_neg  = all_neg[4000:]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "test_y  = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))\n",
        "\n",
        "print(\"Train size:\", len(train_x))\n",
        "print(\"Test size:\", len(test_x))"
      ],
      "id": "TNOxaIUdyXPh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiQUWdIlyXPj"
      },
      "outputs": [],
      "source": [
        "def sentiwordnet_score(word):\n",
        "    synsets = list(swn.senti_synsets(word))\n",
        "    if len(synsets) == 0:\n",
        "        return 0.0\n",
        "    pos_score = np.mean([s.pos_score() for s in synsets])\n",
        "    neg_score = np.mean([s.neg_score() for s in synsets])\n",
        "    return pos_score - neg_score"
      ],
      "id": "yiQUWdIlyXPj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLAL277_yXPl"
      },
      "outputs": [],
      "source": [
        "def count_tweets(result, tweets, ys):\n",
        "    for y, tweet in zip(ys, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            key = (word, y)\n",
        "            result[key] = result.get(key, 0) + 1\n",
        "    return result\n",
        "\n",
        "freqs = count_tweets({}, train_x, train_y)\n",
        "print(\"Унікальних пар:\", len(freqs))"
      ],
      "id": "iLAL277_yXPl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm5uDYATyXPm"
      },
      "outputs": [],
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    loglikelihood = {}\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    N_pos = N_neg = 0\n",
        "    for (w, cls), count in freqs.items():\n",
        "        if cls == 1:\n",
        "            N_pos += count\n",
        "        else:\n",
        "            N_neg += count\n",
        "\n",
        "    D_pos = sum(train_y)\n",
        "    D_neg = len(train_y) - D_pos\n",
        "\n",
        "    logprior = np.log(D_pos) - np.log(D_neg)\n",
        "\n",
        "    for word in vocab:\n",
        "        freq_pos = freqs.get((word, 1), 0)\n",
        "        freq_neg = freqs.get((word, 0), 0)\n",
        "\n",
        "        p_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "        base_ll = np.log(p_pos / p_neg)\n",
        "        senti = sentiwordnet_score(word)\n",
        "\n",
        "        loglikelihood[word] = base_ll + senti\n",
        "\n",
        "    return logprior, loglikelihood\n",
        "\n",
        "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
        "print(\"Навчено.\")"
      ],
      "id": "Rm5uDYATyXPm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNS26NKQyXPn"
      },
      "outputs": [],
      "source": [
        "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
        "    words = process_tweet(tweet)\n",
        "    p = logprior\n",
        "    for w in words:\n",
        "        if w in loglikelihood:\n",
        "            p += loglikelihood[w]\n",
        "    return p"
      ],
      "id": "LNS26NKQyXPn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45B_E29yyXPp"
      },
      "outputs": [],
      "source": [
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    y_hat = []\n",
        "    for t in test_x:\n",
        "        p = naive_bayes_predict(t, logprior, loglikelihood)\n",
        "        y_hat.append(1 if p > 0 else 0)\n",
        "    return np.mean(np.array(y_hat) == test_y)\n",
        "\n",
        "acc = test_naive_bayes(test_x, test_y, logprior, loglikelihood)\n",
        "print(\"Точність:\", acc)"
      ],
      "id": "45B_E29yyXPp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqjShwJAyXPq"
      },
      "outputs": [],
      "source": [
        "def get_ratio(freqs, word):\n",
        "    pos = freqs.get((word, 1), 0)\n",
        "    neg = freqs.get((word, 0), 0)\n",
        "    return (pos + 1) / (neg + 1)\n",
        "\n",
        "ratios = {w: get_ratio(freqs, w) for w in list(set([k[0] for k in freqs.keys()]))}\n",
        "\n",
        "top_pos = sorted(ratios.items(), key=lambda x: -x[1])[:20]\n",
        "top_neg = sorted(ratios.items(), key=lambda x: x[1])[:20]\n",
        "\n",
        "print(\"ТОП позитивні слова:\\n\", top_pos)\n",
        "print(\"\\nТОП негативні слова:\\n\", top_neg)"
      ],
      "id": "dqjShwJAyXPq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHBcA2S_yXPr"
      },
      "outputs": [],
      "source": [
        "print(\"Помилки класифікації:\")\n",
        "for x, y in zip(test_x, test_y):\n",
        "    p = naive_bayes_predict(x, logprior, loglikelihood)\n",
        "    y_hat = 1 if p > 0 else 0\n",
        "    if y != y_hat:\n",
        "        print(y, y_hat, process_tweet(x))"
      ],
      "id": "vHBcA2S_yXPr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2vAPb_QyXPs"
      },
      "outputs": [],
      "source": [
        "my_tweet = \"This course is awesome and I love learning new things!\"\n",
        "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
        "print(\"Мій твіт:\", my_tweet)\n",
        "print(\"Полярність:\", \"Позитивна\" if p > 0 else \"Негативна\")"
      ],
      "id": "z2vAPb_QyXPs"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}