{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iv-alex-glitch/labs-for-uni/blob/main/human-machineinteractionlab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126f1cbb",
      "metadata": {
        "id": "126f1cbb"
      },
      "source": [
        "# Лабораторна робота\n",
        "## Логістична регресія для аналізу тональності текстів\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22115037",
      "metadata": {
        "id": "22115037"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a251d715",
      "metadata": {
        "id": "a251d715"
      },
      "source": [
        "### Попередня обробка тексту"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "428f7f79",
      "metadata": {
        "id": "428f7f79"
      },
      "outputs": [],
      "source": [
        "\n",
        "stemmer = PorterStemmer()\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "stopwords_english = stopwords.words('english')\n",
        "\n",
        "def process_tweet(tweet):\n",
        "    tweet = re.sub(r'https?://\\S+', '', tweet)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    tokens = tokenizer.tokenize(tweet.lower())\n",
        "    clean = []\n",
        "    for w in tokens:\n",
        "        if w not in stopwords_english and w not in string.punctuation:\n",
        "            clean.append(stemmer.stem(w))\n",
        "    return clean\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8b4f0c4",
      "metadata": {
        "id": "a8b4f0c4"
      },
      "source": [
        "### Побудова словника частотностей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa407002",
      "metadata": {
        "id": "fa407002"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_freqs(tweets, ys):\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(ys, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, int(y))\n",
        "            freqs[pair] = freqs.get(pair, 0) + 1\n",
        "    return freqs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b22e33",
      "metadata": {
        "id": "e8b22e33"
      },
      "source": [
        "### Функція ознак"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c17879",
      "metadata": {
        "id": "38c17879"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_features(tweet, freqs):\n",
        "    words = process_tweet(tweet)\n",
        "    x = np.zeros((1, 3))\n",
        "    x[0,0] = 1\n",
        "    for w in words:\n",
        "        x[0,1] += freqs.get((w,1), 0)\n",
        "        x[0,2] += freqs.get((w,0), 0)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "371f05e5",
      "metadata": {
        "id": "371f05e5"
      },
      "source": [
        "### Логістична регресія"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3930b8b4",
      "metadata": {
        "id": "3930b8b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def gradient_descent(X, y, theta, alpha, iters):\n",
        "    m = X.shape[0]\n",
        "    J_hist = []\n",
        "    for i in range(iters):\n",
        "        h = sigmoid(X @ theta)\n",
        "        theta -= (alpha/m) * (X.T @ (h - y))\n",
        "        if i % 50 == 0:\n",
        "            loss = -(1/m) * np.sum(y*np.log(h+1e-12) + (1-y)*np.log(1-h+1e-12))\n",
        "            J_hist.append(loss)\n",
        "    return theta, J_hist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1323567",
      "metadata": {
        "id": "b1323567"
      },
      "source": [
        "### Завантаження датасету Twitter Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea713394",
      "metadata": {
        "id": "ea713394"
      },
      "outputs": [],
      "source": [
        "\n",
        "pos = twitter_samples.strings('positive_tweets.json')[:4000]\n",
        "neg = twitter_samples.strings('negative_tweets.json')[:4000]\n",
        "\n",
        "train_x = pos + neg\n",
        "train_y = np.append(np.ones(len(pos)), np.zeros(len(neg))).reshape(-1,1)\n",
        "\n",
        "freqs = build_freqs(train_x, train_y)\n",
        "\n",
        "X = np.vstack([extract_features(t, freqs) for t in train_x])\n",
        "y = train_y\n",
        "\n",
        "theta = np.zeros((3,1))\n",
        "theta, losses = gradient_descent(X, y, theta, alpha=1e-9, iters=1500)\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.title(\"Loss curve\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a812358",
      "metadata": {
        "id": "4a812358"
      },
      "source": [
        "### Тестування моделі"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcb033fe",
      "metadata": {
        "id": "dcb033fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict(tweet, freqs, theta):\n",
        "    x = extract_features(tweet, freqs)\n",
        "    return sigmoid(x @ theta)\n",
        "\n",
        "print(predict(\"I love this movie!\", freqs, theta))\n",
        "print(predict(\"This is terrible\", freqs, theta))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}