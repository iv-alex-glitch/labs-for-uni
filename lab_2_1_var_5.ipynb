{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Лабораторна робота **No. 2.1** студентки **Іванченко О. В.**\n",
        "\n",
        "Тема: Нейронні мережі для задач класифікації."
      ],
      "metadata": {
        "id": "SO-kqx0ml925"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rpb_vsAml-Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "###Завдання  1. Вибір варіанту завдання\n",
        "  - Оберіть один з 10 варіантів завдань відповідно до свого номеру в групі або за вказівкою викладача.\n",
        "\n",
        "        Варіант 5: Wine Dataset\n",
        "        Опис: Класифікація зразків вина за різними сортами на основі хімічного аналізу.\n",
        "              Особливості набору даних: 13 ознак, 3 класи (різні типи вина)"
      ],
      "metadata": {
        "id": "4j7kcPIelbXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "###Завдання  2. Підготовка даних\n",
        "  - Імпортуйте необхідні бібліотеки\n",
        "  - Завантажте дані відповідно до вашого варіанту\n",
        "  - Візуалізуйте дані для розуміння їх структури\n",
        "  - Поділіть дані на тренувальну та тестову вибірки\n",
        "  - Виконайте нормалізацію/стандартизацію даних"
      ],
      "metadata": {
        "id": "7FE37VmalcxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# встановлюємо пакет, приховуємо вивід\n",
        "!pip install gradio > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "iaFCj1dLoVr6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Імпортування бібліотек\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.datasets import load_breast_cancer, load_wine, load_digits, fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "import gradio as gr\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Ikr-WD24le3H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функції для завантаження наборів даних\n",
        "def load_data(variant):\n",
        "    if variant == 1:  # Breast Cancer Wisconsin\n",
        "        data = load_breast_cancer()\n",
        "        X = data.data\n",
        "        y = data.target\n",
        "        feature_names = data.feature_names\n",
        "        class_names = data.target_names\n",
        "        return X, y, feature_names, class_names, \"Breast Cancer Wisconsin\"\n",
        "\n",
        "    elif variant == 10:  # MNIST Digits\n",
        "        digits = load_digits()\n",
        "        X = digits.data  # 64 пікселі (8x8)\n",
        "        y = digits.target\n",
        "        feature_names = [f\"pixel_{i}\" for i in range(X.shape[1])]\n",
        "        class_names = [str(i) for i in range(10)]\n",
        "        return X, y, feature_names, class_names, \"MNIST Digits\"\n",
        "\n",
        "    elif variant == 3:  # Pima Indians Diabetes\n",
        "        try:\n",
        "            url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "            columns = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "            data = pd.read_csv(url, names=columns)\n",
        "            X = data.iloc[:, :-1].values\n",
        "            y = data.iloc[:, -1].values\n",
        "            feature_names = columns[:-1]\n",
        "            class_names = [\"No Diabetes\", \"Diabetes\"]\n",
        "            return X, y, feature_names, class_names, \"Pima Indians Diabetes\"\n",
        "        except:\n",
        "            # Fallback на випадок, якщо набір даних недоступний\n",
        "            data = load_breast_cancer()\n",
        "            X = data.data\n",
        "            y = data.target\n",
        "            feature_names = data.feature_names\n",
        "            class_names = data.target_names\n",
        "            return X, y, feature_names, class_names, \"Fallback: Breast Cancer Wisconsin (URL Error)\"\n",
        "\n",
        "    elif variant == 4:  # Wine Quality (Red)\n",
        "        try:\n",
        "            url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "            data = pd.read_csv(url, sep=';')\n",
        "            X = data.drop('quality', axis=1).values\n",
        "            y = (data['quality'] >= 6).astype(int)  # Бінаризація: 0 (низька) і 1 (висока)\n",
        "            feature_names = data.drop('quality', axis=1).columns.tolist()\n",
        "            class_names = [\"Low Quality\", \"High Quality\"]\n",
        "            print(f\"Unique values in y: {np.unique(y)}\")  # Має вивести [0, 1]\n",
        "            return X, y, feature_names, class_names, \"Wine Quality (Red)\"\n",
        "        except:\n",
        "            # Fallback на випадок, якщо набір даних недоступний\n",
        "            data = load_breast_cancer()\n",
        "            X = data.data\n",
        "            y = data.target\n",
        "            feature_names = data.feature_names\n",
        "            class_names = data.target_names\n",
        "            return X, y, feature_names, class_names, \"Fallback: Breast Cancer Wisconsin (URL Error)\"\n",
        "\n",
        "    elif variant == 5:  # Wine Dataset\n",
        "        data = load_wine()\n",
        "        X = data.data\n",
        "        y = data.target\n",
        "        feature_names = data.feature_names\n",
        "        class_names = data.target_names\n",
        "        return X, y, feature_names, class_names, \"Wine Dataset\"\n",
        "\n",
        "    elif variant == 6:  # Titanic\n",
        "        try:\n",
        "            url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "            data = pd.read_csv(url)\n",
        "            # Базова обробка даних\n",
        "            data = data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "            # Заповнення пропущених значень\n",
        "            data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "            data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "            # Перетворення категоріальних змінних\n",
        "            data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "            data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
        "\n",
        "            X = data.drop('Survived', axis=1).values\n",
        "            y = data['Survived'].values\n",
        "            feature_names = data.drop('Survived', axis=1).columns.tolist()\n",
        "            class_names = [\"Did not survive\", \"Survived\"]\n",
        "            return X, y, feature_names, class_names, \"Titanic\"\n",
        "        except:\n",
        "            # Fallback на випадок, якщо набір даних недоступний\n",
        "            data = load_breast_cancer()\n",
        "            X = data.data\n",
        "            y = data.target\n",
        "            feature_names = data.feature_names\n",
        "            class_names = data.target_names\n",
        "            return X, y, feature_names, class_names, \"Fallback: Breast Cancer Wisconsin (URL Error)\"\n",
        "\n",
        "    elif variant == 7:  # Heart Disease\n",
        "        try:\n",
        "            url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "            columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
        "            data = pd.read_csv(url, names=columns, na_values='?')\n",
        "            # Обробка пропущених значень\n",
        "            data.dropna(inplace=True)\n",
        "\n",
        "            # Перетворення цільової змінної на бінарну\n",
        "            data['target'] = (data['target'] > 0).astype(int)\n",
        "\n",
        "            X = data.drop('target', axis=1).values\n",
        "            y = data['target'].values\n",
        "            feature_names = columns[:-1]\n",
        "            class_names = [\"No Heart Disease\", \"Heart Disease\"]\n",
        "            return X, y, feature_names, class_names, \"Heart Disease\"\n",
        "        except:\n",
        "            # Fallback на випадок, якщо набір даних недоступний\n",
        "            data = load_breast_cancer()\n",
        "            X = data.data\n",
        "            y = data.target\n",
        "            feature_names = data.feature_names\n",
        "            class_names = data.target_names\n",
        "            return X, y, feature_names, class_names, \"Fallback: Breast Cancer Wisconsin (URL Error)\"\n",
        "\n",
        "    elif variant == 8:  # Iris\n",
        "        try:\n",
        "            url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "            columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
        "            data = pd.read_csv(url, names=columns)\n",
        "\n",
        "            # Перетворення категоріальних міток класу\n",
        "            class_mapping = {\n",
        "                'Iris-setosa': 0,\n",
        "                'Iris-versicolor': 1,\n",
        "                'Iris-virginica': 2\n",
        "            }\n",
        "            data['class'] = data['class'].map(class_mapping)\n",
        "\n",
        "            X = data.iloc[:, :-1].values\n",
        "            y = data.iloc[:, -1].values\n",
        "            feature_names = columns[:-1]\n",
        "            class_names = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
        "            return X, y, feature_names, class_names, \"Iris\"\n",
        "        except:\n",
        "            # Fallback на випадок, якщо набір даних недоступний\n",
        "            data = load_breast_cancer()\n",
        "            X = data.data\n",
        "            y = data.target\n",
        "            feature_names = data.feature_names\n",
        "            class_names = data.target_names\n",
        "            return X, y, feature_names, class_names, \"Fallback: Breast Cancer Wisconsin (URL Error)\"\n",
        "\n",
        "    elif variant == 9:  # Mushroom Dataset\n",
        "        try:\n",
        "            url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
        "            columns = ['class', 'cap_shape', 'cap_surface', 'cap_color', 'bruises', 'odor',\n",
        "                    'gill_attachment', 'gill_spacing', 'gill_size', 'gill_color',\n",
        "                    'stalk_shape', 'stalk_root', 'stalk_surface_above_ring',\n",
        "                    'stalk_surface_below_ring', 'stalk_color_above_ring',\n",
        "                    'stalk_color_below_ring', 'veil_type', 'veil_color',\n",
        "                    'ring_number', 'ring_type', 'spore_print_color', 'population', 'habitat']\n",
        "\n",
        "            data = pd.read_csv(url, names=columns)\n",
        "\n",
        "            # Замінюємо категоріальні ознаки на числові\n",
        "            data_encoded = pd.get_dummies(data.drop('class', axis=1))\n",
        "\n",
        "            # Перетворюємо цільову змінну\n",
        "            data['class'] = data['class'].map({'e': 0, 'p': 1})\n",
        "\n",
        "            X = data_encoded.values\n",
        "            y = data['class'].values\n",
        "            feature_names = data_encoded.columns.tolist()\n",
        "            class_names = [\"Edible\", \"Poisonous\"]\n",
        "            return X, y, feature_names, class_names, \"Mushroom Dataset\"\n",
        "        except:\n",
        "            # Fallback на випадок, якщо набір даних недоступний\n",
        "            data = load_breast_cancer()\n",
        "            X = data.data\n",
        "            y = data.target\n",
        "            feature_names = data.feature_names\n",
        "            class_names = data.target_names\n",
        "            return X, y, feature_names, class_names, \"Fallback: Breast Cancer Wisconsin (URL Error)\"\n",
        "\n",
        "    elif variant == 2:  # Fashion MNIST (обмежений набір)\n",
        "        try:\n",
        "            # Завантажуємо обмежений набір Fashion MNIST для швидкості\n",
        "            (X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "            # Беремо лише підмножину для швидкості\n",
        "            subset_size = 5000\n",
        "            X = np.vstack((X_train[:subset_size], X_test[:subset_size]))\n",
        "            y = np.concatenate((y_train[:subset_size], y_test[:subset_size]))\n",
        "\n",
        "            # Нормалізація і реформування даних\n",
        "            X = X.reshape(-1, 784) / 255.0\n",
        "\n",
        "            feature_names = [f\"pixel_{i}\" for i in range(X.shape[1])]\n",
        "            class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "                           \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "            return X, y, feature_names, class_names, \"Fashion MNIST (subset)\"\n",
        "        except:\n",
        "            # Fallback на випадок, якщо набір даних недоступний\n",
        "            data = load_breast_cancer()\n",
        "            X = data.data\n",
        "            y = data.target\n",
        "            feature_names = data.feature_names\n",
        "            class_names = data.target_names\n",
        "            return X, y, feature_names, class_names, \"Fallback: Breast Cancer Wisconsin (URL Error)\"\n",
        "\n",
        "    else:\n",
        "        # За замовчуванням - Breast Cancer Wisconsin\n",
        "        data = load_breast_cancer()\n",
        "        X = data.data\n",
        "        y = data.target\n",
        "        feature_names = data.feature_names\n",
        "        class_names = data.target_names\n",
        "        return X, y, feature_names, class_names, \"Breast Cancer Wisconsin (Default)\""
      ],
      "metadata": {
        "id": "2B6VacdTnmYr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Візуалізація сирих даних\n",
        "\"\"\"\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# PCA до 2 компонентів\n",
        "pca = PCA(n_components=2)\n",
        "X2 = pca.fit_transform(X)\n",
        "\n",
        "x1 = X2[:,:1]\n",
        "y1 = X2[:,1:]\n",
        "\n",
        "# Побудова графіка\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x1,y1)\n",
        "plt.show()\n",
        "\n",
        "X2.shape\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "snhFEJsismxu",
        "outputId": "060b9d56-1afa-4859-e500-6abe00a15542"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.decomposition import PCA\\n\\n# PCA до 2 компонентів\\npca = PCA(n_components=2)\\nX2 = pca.fit_transform(X)\\n\\nx1 = X2[:,:1]\\ny1 = X2[:,1:]\\n\\n# Побудова графіка\\nplt.figure(figsize=(8, 6))\\nplt.scatter(x1,y1)\\nplt.show()\\n\\nX2.shape\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Поділ даних на тренувальну та тестову вибірки\n",
        "\"\"\"\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3oPELa-ata_q",
        "outputId": "1707d370-edfb-4cda-a244-7d8accd19ed8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=42, stratify=y\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Стандартизаці\"\"\"я даних\n",
        "\"\"\"\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5p2vU1Efuem_",
        "outputId": "1f5c7186-9f9b-44a0-d5e8-bdd3e24dc19a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nscaler = StandardScaler()\\nX_train = scaler.fit_transform(X_train)  \\nX_test = scaler.fit_transform(X_test)      \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення фігури з двома subplot'ами\n",
        "\"\"\"\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# PCA для тренувальних даних\n",
        "pca = PCA(n_components=2)\n",
        "X2_train = pca.fit_transform(X_train)\n",
        "axs[0].scatter(X2_train[:, 0], X2_train[:, 1])\n",
        "axs[0].set_title(\"PCA на X_train\")\n",
        "\n",
        "# PCA для тестових даних\n",
        "pca = PCA(n_components=2)\n",
        "X2_test = pca.fit_transform(X_test)\n",
        "axs[1].scatter(X2_test[:, 0], X2_test[:, 1])\n",
        "axs[1].set_title(\"PCA на X_test\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "2hW8BCajvLLZ",
        "outputId": "9435e05a-d8eb-46fe-c995-d62fe6604aeb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfig, axs = plt.subplots(1, 2, figsize=(14, 6))\\n\\n# PCA для тренувальних даних\\npca = PCA(n_components=2)\\nX2_train = pca.fit_transform(X_train)\\naxs[0].scatter(X2_train[:, 0], X2_train[:, 1])\\naxs[0].set_title(\"PCA на X_train\")\\n\\n# PCA для тестових даних\\npca = PCA(n_components=2)\\nX2_test = pca.fit_transform(X_test)\\naxs[1].scatter(X2_test[:, 0], X2_test[:, 1])\\naxs[1].set_title(\"PCA на X_test\")\\n\\nplt.tight_layout()\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "###Завдання 3. Реалізація моделей нейронних мереж\n",
        "  - Створіть простий багатошаровий перцептрон з використанням TensorFlow/Keras\n",
        "  - Реалізуйте альтернативну модель з використанням scikit-learn\n",
        "  - Експериментуйте з різними архітектурами (кількістю шарів, нейронів, функцій активації)"
      ],
      "metadata": {
        "id": "AuV0SCgElfdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для побудови TensorFlow/Keras моделі\n",
        "\n",
        "def build_keras_model(input_dim, num_classes, architecture, activation='relu', hidden_units=(32, 16), dropout_rate=0.2):\n",
        "    if architecture == \"simple\":\n",
        "        model = Sequential([\n",
        "            Dense(hidden_units[0], activation=activation, input_shape=(input_dim,)),\n",
        "            Dense(hidden_units[1], activation=activation),\n",
        "            Dense(1 if num_classes == 2 else num_classes,\n",
        "                  activation='sigmoid' if num_classes == 2 else 'softmax')\n",
        "        ])\n",
        "    elif architecture == \"cnn\":\n",
        "        if input_dim == 784:  # Для Fashion MNIST\n",
        "            input_img = Input(shape=(input_dim,))\n",
        "            x = tf.reshape(input_img, [-1, 28, 28, 1])\n",
        "            x = Conv2D(32, kernel_size=(3, 3), activation='relu')(x)\n",
        "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "            x = Flatten()(x)\n",
        "            x = Dense(128, activation='relu')(x)\n",
        "            x = Dropout(0.5)(x)\n",
        "            outputs = Dense(1 if num_classes == 2 else num_classes,\n",
        "                            activation='sigmoid' if num_classes == 2 else 'softmax')(x)\n",
        "            model = Model(inputs=input_img, outputs=outputs)\n",
        "        elif input_dim == 64:  # Для MNIST Digits\n",
        "            input_img = Input(shape=(input_dim,))\n",
        "            x = tf.reshape(input_img, [-1, 8, 8, 1])  # Правильний розмір для 8x8\n",
        "            x = Conv2D(32, kernel_size=(2, 2), activation='relu')(x)  # Менше ядро\n",
        "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "            x = Flatten()(x)\n",
        "            x = Dense(128, activation='relu')(x)\n",
        "            x = Dropout(0.5)(x)\n",
        "            outputs = Dense(1 if num_classes == 2 else num_classes,\n",
        "                            activation='sigmoid' if num_classes == 2 else 'softmax')(x)\n",
        "            model = Model(inputs=input_img, outputs=outputs)\n",
        "        else:\n",
        "            # Fallback на повнозв’язну модель\n",
        "            model = Sequential([\n",
        "                Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "                Dense(64, activation='relu'),\n",
        "                Dense(1 if num_classes == 2 else num_classes,\n",
        "                      activation='sigmoid' if num_classes == 2 else 'softmax')\n",
        "            ])\n",
        "    else:\n",
        "        # Fallback на просту модель\n",
        "        model = Sequential([\n",
        "            Dense(hidden_units[0], activation=activation, input_shape=(input_dim,)),\n",
        "            Dense(hidden_units[1], activation=activation),\n",
        "            Dense(1 if num_classes == 2 else num_classes,\n",
        "                  activation='sigmoid' if num_classes == 2 else 'softmax')\n",
        "        ])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "lyOodUwQlfpa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для тренування TensorFlow/Keras моделі\n",
        "def train_keras_model(model, X_train, y_train, X_test, y_test, num_classes,\n",
        "                      optimizer='adam', learning_rate=0.001, batch_size=32, epochs=50,\n",
        "                      patience=5, verbose=0):\n",
        "\n",
        "    # Перетворення міток тільки для багатокласової класифікації\n",
        "    if num_classes > 2:\n",
        "        y_train_cat = to_categorical(y_train, num_classes)\n",
        "        y_test_cat = to_categorical(y_test, num_classes)\n",
        "    else:\n",
        "        y_train_cat = y_train  # Залишаємо як є для двокласової\n",
        "        y_test_cat = y_test\n",
        "\n",
        "    # Налаштування оптимізатора\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        opt = SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "    # Компіляція моделі\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss='binary_crossentropy' if num_classes == 2 else 'categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Раннє зупинення навчання\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=patience,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Тренування моделі\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        X_train, y_train_cat,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=verbose\n",
        "    )\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Оцінка моделі\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "\n",
        "    # Передбачення\n",
        "    if num_classes > 2:\n",
        "        y_pred_proba = model.predict(X_test)\n",
        "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "    else:\n",
        "        y_pred_proba = model.predict(X_test).flatten()\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'history': history,\n",
        "        'training_time': training_time,\n",
        "        'test_accuracy': test_acc,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }"
      ],
      "metadata": {
        "id": "L_buoiz3L8XB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для тренування scikit-learn моделі\n",
        "\n",
        "def train_sklearn_model(X_train, y_train, X_test, y_test, model_type='mlp',\n",
        "                       hidden_layer_sizes=(32, 16), alpha=0.0001, max_iter=200):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    if model_type == 'mlp':\n",
        "        model = MLPClassifier(\n",
        "            hidden_layer_sizes=hidden_layer_sizes,\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            alpha=alpha,\n",
        "            max_iter=max_iter,\n",
        "            random_state=42\n",
        "        )\n",
        "    elif model_type == 'logistic':\n",
        "        model = LogisticRegression(\n",
        "            C=1/alpha if alpha > 0 else 1e6,\n",
        "            max_iter=max_iter,\n",
        "            random_state=42\n",
        "        )\n",
        "    else:\n",
        "        # За замовчуванням - MLPClassifier\n",
        "        model = MLPClassifier(\n",
        "            hidden_layer_sizes=hidden_layer_sizes,\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            alpha=alpha,\n",
        "            max_iter=max_iter,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    # Навчання моделі\n",
        "    model.fit(X_train, y_train)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Передбачення\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    # Оцінка моделі\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'training_time': training_time,\n",
        "        'test_accuracy': accuracy,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }"
      ],
      "metadata": {
        "id": "pMOWPbBn40By"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для оцінки та порівняння моделей\n",
        "def evaluate_models(y_test, keras_results, sklearn_results, class_names):\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    # Для бінарної класифікації\n",
        "    if num_classes == 2:\n",
        "        keras_precision = precision_score(y_test, keras_results['y_pred'])\n",
        "        keras_recall = recall_score(y_test, keras_results['y_pred'])\n",
        "        keras_f1 = f1_score(y_test, keras_results['y_pred'])\n",
        "\n",
        "        sklearn_precision = precision_score(y_test, sklearn_results['y_pred'])\n",
        "        sklearn_recall = recall_score(y_test, sklearn_results['y_pred'])\n",
        "        sklearn_f1 = f1_score(y_test, sklearn_results['y_pred'])\n",
        "\n",
        "        # ROC криві\n",
        "        keras_fpr, keras_tpr, _ = roc_curve(y_test, keras_results['y_pred_proba'] if num_classes == 2 else keras_results['y_pred_proba'][:, 1])\n",
        "        keras_auc = auc(keras_fpr, keras_tpr)\n",
        "\n",
        "        sklearn_fpr, sklearn_tpr, _ = roc_curve(y_test, sklearn_results['y_pred_proba'][:, 1])\n",
        "        sklearn_auc = auc(sklearn_fpr, sklearn_tpr)\n",
        "\n",
        "        roc_data = {\n",
        "            'keras': {'fpr': keras_fpr, 'tpr': keras_tpr, 'auc': keras_auc},\n",
        "            'sklearn': {'fpr': sklearn_fpr, 'tpr': sklearn_tpr, 'auc': sklearn_auc}\n",
        "        }\n",
        "    else:\n",
        "        # Для багатокласової класифікації\n",
        "        keras_precision = precision_score(y_test, keras_results['y_pred'], average='weighted')\n",
        "        keras_recall = recall_score(y_test, keras_results['y_pred'], average='weighted')\n",
        "        keras_f1 = f1_score(y_test, keras_results['y_pred'], average='weighted')\n",
        "\n",
        "        sklearn_precision = precision_score(y_test, sklearn_results['y_pred'], average='weighted')\n",
        "        sklearn_recall = recall_score(y_test, sklearn_results['y_pred'], average='weighted')\n",
        "        sklearn_f1 = f1_score(y_test, sklearn_results['y_pred'], average='weighted')\n",
        "\n",
        "        roc_data = None  # ROC криві не обчислюються для багатокласової класифікації в цьому прикладі\n",
        "\n",
        "    # Матриці помилок\n",
        "    keras_cm = confusion_matrix(y_test, keras_results['y_pred'])\n",
        "    sklearn_cm = confusion_matrix(y_test, sklearn_results['y_pred'])\n",
        "\n",
        "    return {\n",
        "        'keras': {\n",
        "            'accuracy': keras_results['test_accuracy'],\n",
        "            'precision': keras_precision,\n",
        "            'recall': keras_recall,\n",
        "            'f1': keras_f1,\n",
        "            'cm': keras_cm,\n",
        "            'training_time': keras_results['training_time']\n",
        "        },\n",
        "        'sklearn': {\n",
        "            'accuracy': sklearn_results['test_accuracy'],\n",
        "            'precision': sklearn_precision,\n",
        "            'recall': sklearn_recall,\n",
        "            'f1': sklearn_f1,\n",
        "            'cm': sklearn_cm,\n",
        "            'training_time': sklearn_results['training_time']\n",
        "        },\n",
        "        'roc_data': roc_data\n",
        "    }\n"
      ],
      "metadata": {
        "id": "xFRsp7_17yax"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        "###Завдання 4. Навчання та оцінка моделей\n",
        "  - Визначте гіперпараметри (швидкість навчання, розмір батчу, кількість епох)\n",
        "  - Навчіть моделі на тренувальних даних\n",
        "  - Оцініть моделі на тестових даних\n",
        "  - Порівняйте точність, час навчання та інші метрики"
      ],
      "metadata": {
        "id": "b8dAsNlhlf3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для відображення метрик моделей\n",
        "def plot_model_metrics(evaluation_results):\n",
        "    keras_metrics = evaluation_results['keras']\n",
        "    sklearn_metrics = evaluation_results['sklearn']\n",
        "\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
        "    keras_values = [keras_metrics[m] for m in metrics]\n",
        "    sklearn_values = [sklearn_metrics[m] for m in metrics]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Порівняння метрик\n",
        "    x = range(len(metrics))\n",
        "    bar_width = 0.35\n",
        "\n",
        "    axes[0].bar([i - bar_width/2 for i in x], keras_values, bar_width, label='Keras', color='#3498db')\n",
        "    axes[0].bar([i + bar_width/2 for i in x], sklearn_values, bar_width, label='Scikit-learn', color='#e74c3c')\n",
        "\n",
        "    axes[0].set_xticks(x)\n",
        "    axes[0].set_xticklabels(metrics)\n",
        "    axes[0].set_ylabel('Score')\n",
        "    axes[0].set_title('Model Performance Metrics')\n",
        "    axes[0].legend()\n",
        "    axes[0].set_ylim(0, 1)\n",
        "\n",
        "    # Порівняння часу тренування\n",
        "    times = [keras_metrics['training_time'], sklearn_metrics['training_time']]\n",
        "    axes[1].bar(['Keras', 'Scikit-learn'], times, color=['#3498db', '#e74c3c'])\n",
        "    axes[1].set_ylabel('Time (seconds)')\n",
        "    axes[1].set_title('Training Time Comparison')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "_dDeCs3-HDMc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Функція для візуалізації межі прийняття рішень (для 2D даних)\n",
        "def plot_decision_boundary(X, y, keras_model, sklearn_model, num_classes):\n",
        "    # Працює тільки з 2 ознаками\n",
        "    if X.shape[1] != 2:\n",
        "        return None\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Створюємо сітку точок\n",
        "    h = 0.02  # крок сітки\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Передбачення для Keras моделі\n",
        "    if num_classes > 2:\n",
        "        Z_keras = np.argmax(keras_model.predict(np.c_[xx.ravel(), yy.ravel()]), axis=1)\n",
        "    else:\n",
        "        Z_keras = (keras_model.predict(np.c_[xx.ravel(), yy.ravel()]) > 0.5).astype(int).flatten()\n",
        "    Z_keras = Z_keras.reshape(xx.shape)\n",
        "\n",
        "    # Передбачення для Scikit-learn моделі\n",
        "    Z_sklearn = sklearn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z_sklearn = Z_sklearn.reshape(xx.shape)\n",
        "\n",
        "    # Відображення меж прийняття рішень\n",
        "    for ax, Z, title in zip(axes, [Z_keras, Z_sklearn], ['Keras Model', 'Scikit-learn Model']):\n",
        "        ax.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
        "        ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
        "        ax.set_title(title)\n",
        "        ax.set_xlabel('Feature 1')\n",
        "        ax.set_ylabel('Feature 2')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "UKpnHMbuLBMt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Основна функція для навчання та оцінки моделей\n",
        "def train_and_evaluate_models(variant, test_size, keras_architecture, sklearn_model_type,\n",
        "                            hidden_units, activation, learning_rate, optimizer, batch_size,\n",
        "                            epochs, dropout_rate, alpha, max_iter, random_state):\n",
        "    # Завантаження даних\n",
        "    X, y, feature_names, class_names, dataset_name = load_data(variant)\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    # Розділення на тренувальні та тестові дані\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size/100, random_state=random_state)\n",
        "\n",
        "    # Стандартизація даних\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Побудова та навчання Keras моделі\n",
        "    keras_model = build_keras_model(\n",
        "        input_dim=X_train_scaled.shape[1],\n",
        "        num_classes=num_classes,\n",
        "        architecture=keras_architecture,\n",
        "        activation=activation,\n",
        "        hidden_units=hidden_units,\n",
        "        dropout_rate=dropout_rate\n",
        "    )\n",
        "\n",
        "    keras_results = train_keras_model(\n",
        "        model=keras_model,\n",
        "        X_train=X_train_scaled,\n",
        "        y_train=y_train,\n",
        "        X_test=X_test_scaled,\n",
        "        y_test=y_test,\n",
        "        num_classes=num_classes,\n",
        "        optimizer=optimizer,\n",
        "        learning_rate=learning_rate,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    # Навчання Scikit-learn моделі\n",
        "    sklearn_results = train_sklearn_model(\n",
        "        X_train=X_train_scaled,\n",
        "        y_train=y_train,\n",
        "        X_test=X_test_scaled,\n",
        "        y_test=y_test,\n",
        "        model_type=sklearn_model_type,\n",
        "        hidden_layer_sizes=hidden_units,\n",
        "        alpha=alpha,\n",
        "        max_iter=max_iter\n",
        "    )\n",
        "\n",
        "    # Оцінка моделей\n",
        "    evaluation_results = evaluate_models(\n",
        "        y_test=y_test,\n",
        "        keras_results=keras_results,\n",
        "        sklearn_results=sklearn_results,\n",
        "        class_names=class_names\n",
        "    )\n",
        "\n",
        "    # Підготовка результатів\n",
        "    results = {\n",
        "        'dataset_name': dataset_name,\n",
        "        'class_names': class_names,\n",
        "        'num_classes': num_classes,\n",
        "        'feature_names': feature_names,\n",
        "        'X_test': X_test_scaled,\n",
        "        'y_test': y_test,\n",
        "        'keras_model': keras_model,\n",
        "        'sklearn_model': sklearn_results['model'],\n",
        "        'keras_history': keras_results['history'],\n",
        "        'keras_pred': keras_results['y_pred'],\n",
        "        'sklearn_pred': sklearn_results['y_pred'],\n",
        "        'evaluation_results': evaluation_results\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "n2ObG3U_HDBn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для оцінки та порівняння моделей\n",
        "def evaluate_models(y_test, keras_results, sklearn_results, class_names):\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    # Для бінарної класифікації\n",
        "    if num_classes == 2:\n",
        "        keras_precision = precision_score(y_test, keras_results['y_pred'])\n",
        "        keras_recall = recall_score(y_test, keras_results['y_pred'])\n",
        "        keras_f1 = f1_score(y_test, keras_results['y_pred'])\n",
        "\n",
        "        sklearn_precision = precision_score(y_test, sklearn_results['y_pred'])\n",
        "        sklearn_recall = recall_score(y_test, sklearn_results['y_pred'])\n",
        "        sklearn_f1 = f1_score(y_test, sklearn_results['y_pred'])\n",
        "\n",
        "        # ROC криві\n",
        "        keras_fpr, keras_tpr, _ = roc_curve(y_test, keras_results['y_pred_proba'] if num_classes == 2 else keras_results['y_pred_proba'][:, 1])\n",
        "        keras_auc = auc(keras_fpr, keras_tpr)\n",
        "\n",
        "        sklearn_fpr, sklearn_tpr, _ = roc_curve(y_test, sklearn_results['y_pred_proba'][:, 1])\n",
        "        sklearn_auc = auc(sklearn_fpr, sklearn_tpr)\n",
        "\n",
        "        roc_data = {\n",
        "            'keras': {'fpr': keras_fpr, 'tpr': keras_tpr, 'auc': keras_auc},\n",
        "            'sklearn': {'fpr': sklearn_fpr, 'tpr': sklearn_tpr, 'auc': sklearn_auc}\n",
        "        }\n",
        "    else:\n",
        "        # Для багатокласової класифікації\n",
        "        keras_precision = precision_score(y_test, keras_results['y_pred'], average='weighted')\n",
        "        keras_recall = recall_score(y_test, keras_results['y_pred'], average='weighted')\n",
        "        keras_f1 = f1_score(y_test, keras_results['y_pred'], average='weighted')\n",
        "\n",
        "        sklearn_precision = precision_score(y_test, sklearn_results['y_pred'], average='weighted')\n",
        "        sklearn_recall = recall_score(y_test, sklearn_results['y_pred'], average='weighted')\n",
        "        sklearn_f1 = f1_score(y_test, sklearn_results['y_pred'], average='weighted')\n",
        "\n",
        "        roc_data = None  # ROC криві не обчислюються для багатокласової класифікації в цьому прикладі\n",
        "\n",
        "    # Матриці помилок\n",
        "    keras_cm = confusion_matrix(y_test, keras_results['y_pred'])\n",
        "    sklearn_cm = confusion_matrix(y_test, sklearn_results['y_pred'])\n",
        "\n",
        "    return {\n",
        "        'keras': {\n",
        "            'accuracy': keras_results['test_accuracy'],\n",
        "            'precision': keras_precision,\n",
        "            'recall': keras_recall,\n",
        "            'f1': keras_f1,\n",
        "            'cm': keras_cm,\n",
        "            'training_time': keras_results['training_time']\n",
        "        },\n",
        "        'sklearn': {\n",
        "            'accuracy': sklearn_results['test_accuracy'],\n",
        "            'precision': sklearn_precision,\n",
        "            'recall': sklearn_recall,\n",
        "            'f1': sklearn_f1,\n",
        "            'cm': sklearn_cm,\n",
        "            'training_time': sklearn_results['training_time']\n",
        "        },\n",
        "        'roc_data': roc_data\n",
        "    }\n"
      ],
      "metadata": {
        "id": "NF34WeBuHC6M"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        "###Завдання 5. Аналіз результатів\n",
        "- Візуалізуйте криві навчання\n",
        "- Побудуйте матриці помилок\n",
        "- Для бінарної класифікації побудуйте ROC криві\n",
        "- Проаналізуйте приклади помилково класифікованих зразків\n",
        "- Спробуйте різні методи для покращення продуктивності"
      ],
      "metadata": {
        "id": "j3JUE2cKmiG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для відображення кривої навчання\n",
        "\n",
        "def plot_keras_learning_curves(history):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Графік втрат\n",
        "    axes[0].plot(history.history['loss'], label='Train Loss')\n",
        "    axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
        "    axes[0].set_title('Loss Curves')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Графік точності\n",
        "    axes[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    axes[1].set_title('Accuracy Curves')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "wMih67Xolgo0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для відображення матриць помилок\n",
        "\n",
        "def plot_confusion_matrices(evaluation_results, class_names):\n",
        "    keras_cm = evaluation_results['keras']['cm']\n",
        "    sklearn_cm = evaluation_results['sklearn']['cm']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Матриця помилок для Keras моделі\n",
        "    sns.heatmap(keras_cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    axes[0].set_title('Keras Model Confusion Matrix')\n",
        "    axes[0].set_xlabel('Predicted')\n",
        "    axes[0].set_ylabel('True')\n",
        "\n",
        "    # Матриця помилок для Scikit-learn моделі\n",
        "    sns.heatmap(sklearn_cm, annot=True, fmt='d', cmap='Reds', ax=axes[1],\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    axes[1].set_title('Scikit-learn Model Confusion Matrix')\n",
        "    axes[1].set_xlabel('Predicted')\n",
        "    axes[1].set_ylabel('True')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "DIdy4Ytr8syQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для відображення ROC кривих (для бінарної класифікації)\n",
        "\n",
        "def plot_roc_curves(evaluation_results):\n",
        "    roc_data = evaluation_results['roc_data']\n",
        "\n",
        "    if roc_data is None:\n",
        "        return None\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # ROC крива для Keras моделі\n",
        "    ax.plot(roc_data['keras']['fpr'], roc_data['keras']['tpr'],\n",
        "            label=f'Keras (AUC = {roc_data[\"keras\"][\"auc\"]:.3f})',\n",
        "            color='#3498db', linewidth=2)\n",
        "\n",
        "    # ROC крива для Scikit-learn моделі\n",
        "    ax.plot(roc_data['sklearn']['fpr'], roc_data['sklearn']['tpr'],\n",
        "            label=f'Scikit-learn (AUC = {roc_data[\"sklearn\"][\"auc\"]:.3f})',\n",
        "            color='#e74c3c', linewidth=2)\n",
        "\n",
        "    # Базова лінія\n",
        "    ax.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title('Receiver Operating Characteristic (ROC) Curves')\n",
        "    ax.legend(loc='lower right')\n",
        "\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "CCY5penL8sk8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для відображення прикладів помилково класифікованих зразків\n",
        "def plot_misclassifications(X_test, y_test, keras_pred, sklearn_pred, dataset_name, class_names):\n",
        "    # Визначення, які зразки були неправильно класифіковані\n",
        "    keras_errors = (y_test != keras_pred)\n",
        "    sklearn_errors = (y_test != sklearn_pred)\n",
        "\n",
        "    # Зразки, які обидві моделі класифікували неправильно\n",
        "    common_errors = keras_errors & sklearn_errors\n",
        "\n",
        "    # Зразки, які Keras класифікував правильно, а Scikit-learn - ні\n",
        "    keras_correct_sklearn_wrong = ~keras_errors & sklearn_errors\n",
        "\n",
        "    # Зразки, які Scikit-learn класифікував правильно, а Keras - ні\n",
        "    keras_wrong_sklearn_correct = keras_errors & ~sklearn_errors\n",
        "\n",
        "    # Перевірка, чи це дані зображень\n",
        "    is_image_data = dataset_name in [\"MNIST Digits\", \"Fashion MNIST (subset)\"]\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "    plt.suptitle(f\"Misclassification Examples\", fontsize=16)\n",
        "\n",
        "    # Визначення зразків для відображення\n",
        "    if np.sum(common_errors) > 0:\n",
        "        indices = np.where(common_errors)[0]\n",
        "        n_samples = min(5, len(indices))\n",
        "        selected_indices = indices[:n_samples]\n",
        "\n",
        "        for i, idx in enumerate(selected_indices):\n",
        "            plt.subplot(3, 5, i + 1)\n",
        "\n",
        "            if is_image_data:\n",
        "                # Якщо це зображення, відображаємо його як зображення\n",
        "                img = X_test[idx].reshape(28, 28)\n",
        "                plt.imshow(img, cmap='gray')\n",
        "            else:\n",
        "                # Для інших даних відображаємо гістограму ознак\n",
        "                plt.bar(range(min(10, X_test.shape[1])), X_test[idx][:min(10, X_test.shape[1])])\n",
        "\n",
        "            plt.title(f\"True: {class_names[y_test[idx]]}\\nBoth Wrong\", fontsize=9)\n",
        "            plt.axis('off')\n",
        "\n",
        "    # Зразки, які Keras класифікував правильно, а Scikit-learn - ні\n",
        "    if np.sum(keras_correct_sklearn_wrong) > 0:\n",
        "        indices = np.where(keras_correct_sklearn_wrong)[0]\n",
        "        n_samples = min(5, len(indices))\n",
        "        selected_indices = indices[:n_samples]\n",
        "\n",
        "        for i, idx in enumerate(selected_indices):\n",
        "            plt.subplot(3, 5, i + 6)\n",
        "\n",
        "            if is_image_data:\n",
        "                img = X_test[idx].reshape(28, 28)\n",
        "                plt.imshow(img, cmap='gray')\n",
        "            else:\n",
        "                plt.bar(range(min(10, X_test.shape[1])), X_test[idx][:min(10, X_test.shape[1])])\n",
        "\n",
        "            plt.title(f\"True: {class_names[y_test[idx]]}\\nKeras Correct\", fontsize=9)\n",
        "            plt.axis('off')\n",
        "\n",
        "    # Зразки, які Scikit-learn класифікував правильно, а Keras - ні\n",
        "    if np.sum(keras_wrong_sklearn_correct) > 0:\n",
        "        indices = np.where(keras_wrong_sklearn_correct)[0]\n",
        "        n_samples = min(5, len(indices))\n",
        "        selected_indices = indices[:n_samples]\n",
        "\n",
        "        for i, idx in enumerate(selected_indices):\n",
        "            plt.subplot(3, 5, i + 11)\n",
        "\n",
        "            if is_image_data:\n",
        "                img = X_test[idx].reshape(28, 28)\n",
        "                plt.imshow(img, cmap='gray')\n",
        "            else:\n",
        "                plt.bar(range(min(10, X_test.shape[1])), X_test[idx][:min(10, X_test.shape[1])])\n",
        "\n",
        "            plt.title(f\"True: {class_names[y_test[idx]]}\\nScikit-learn Correct\", fontsize=9)\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    return fig"
      ],
      "metadata": {
        "id": "l46Ihvca8sda"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        "###Завдання 6. Створення інтерактивного інтерфейсу\n",
        "- Використайте gradio для створення інтерактивного інтерфейсу\n",
        "- Додайте можливість вибору різних параметрів моделі\n",
        "- Забезпечте візуалізацію результатів"
      ],
      "metadata": {
        "id": "Dz7xi3mgmqEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція для представлення результатів у вигляді текстового звіту\n",
        "def generate_results_text(results):\n",
        "    dataset_name = results['dataset_name']\n",
        "    num_classes = results['num_classes']\n",
        "    keras_metrics = results['evaluation_results']['keras']\n",
        "    sklearn_metrics = results['evaluation_results']['sklearn']\n",
        "\n",
        "    output_text = f\"## Результати аналізу для набору даних: {dataset_name}\\n\\n\"\n",
        "    output_text += f\"Кількість класів: {num_classes}\\n\\n\"\n",
        "\n",
        "    output_text += \"### Метрики Keras моделі:\\n\"\n",
        "    output_text += f\"- Точність (Accuracy): {keras_metrics['accuracy']:.4f}\\n\"\n",
        "    output_text += f\"- Precision: {keras_metrics['precision']:.4f}\\n\"\n",
        "    output_text += f\"- Recall: {keras_metrics['recall']:.4f}\\n\"\n",
        "    output_text += f\"- F1-міра: {keras_metrics['f1']:.4f}\\n\"\n",
        "    output_text += f\"- Час навчання: {keras_metrics['training_time']:.2f} секунд\\n\\n\"\n",
        "\n",
        "    output_text += \"### Метрики Scikit-learn моделі:\\n\"\n",
        "    output_text += f\"- Точність (Accuracy): {sklearn_metrics['accuracy']:.4f}\\n\"\n",
        "    output_text += f\"- Precision: {sklearn_metrics['precision']:.4f}\\n\"\n",
        "    output_text += f\"- Recall: {sklearn_metrics['recall']:.4f}\\n\"\n",
        "    output_text += f\"- F1-міра: {sklearn_metrics['f1']:.4f}\\n\"\n",
        "    output_text += f\"- Час навчання: {sklearn_metrics['training_time']:.2f} секунд\\n\\n\"\n",
        "\n",
        "    # Додаємо порівняння\n",
        "    keras_correct = np.sum(results['y_test'] == results['keras_pred'])\n",
        "    sklearn_correct = np.sum(results['y_test'] == results['sklearn_pred'])\n",
        "    total_samples = len(results['y_test'])\n",
        "\n",
        "    output_text += \"### Порівняння моделей:\\n\"\n",
        "    output_text += f\"- Загальна кількість зразків у тестовому наборі: {total_samples}\\n\"\n",
        "    output_text += f\"- Keras правильно класифікувала: {keras_correct} зразків ({keras_correct/total_samples*100:.2f}%)\\n\"\n",
        "    output_text += f\"- Scikit-learn правильно класифікувала: {sklearn_correct} зразків ({sklearn_correct/total_samples*100:.2f}%)\\n\"\n",
        "\n",
        "    # Зразки, які обидві моделі класифікували неправильно\n",
        "    both_wrong = np.sum((results['y_test'] != results['keras_pred']) & (results['y_test'] != results['sklearn_pred']))\n",
        "    output_text += f\"- Кількість зразків, неправильно класифікованих обома моделями: {both_wrong} ({both_wrong/total_samples*100:.2f}%)\\n\"\n",
        "\n",
        "    return output_text"
      ],
      "metadata": {
        "id": "SaufwQU4KmTr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_interface(variant, test_size, keras_architecture, sklearn_model_type,\n",
        "                   first_layer_units, second_layer_units, activation, learning_rate,\n",
        "                   optimizer, batch_size, epochs, dropout_rate, alpha, max_iter, random_state):\n",
        "\n",
        "    hidden_units = (first_layer_units, second_layer_units)\n",
        "\n",
        "    try:\n",
        "        results = train_and_evaluate_models(\n",
        "            variant=variant,\n",
        "            test_size=test_size,\n",
        "            keras_architecture=keras_architecture,\n",
        "            sklearn_model_type=sklearn_model_type,\n",
        "            hidden_units=hidden_units,\n",
        "            activation=activation,\n",
        "            learning_rate=learning_rate,\n",
        "            optimizer=optimizer,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            dropout_rate=dropout_rate,\n",
        "            alpha=alpha,\n",
        "            max_iter=max_iter,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        # Генерація текстового звіту\n",
        "        output_text = generate_results_text(results)\n",
        "\n",
        "        # Візуалізація\n",
        "        learning_curve_plot = plot_keras_learning_curves(results['keras_history'])\n",
        "        metrics_plot = plot_model_metrics(results['evaluation_results'])\n",
        "        cm_plot = plot_confusion_matrices(results['evaluation_results'],\n",
        "                                       results['class_names'][:min(10, len(results['class_names']))])\n",
        "\n",
        "        misclassifications_plot = plot_misclassifications(\n",
        "            results['X_test'], results['y_test'],\n",
        "            results['keras_pred'], results['sklearn_pred'],\n",
        "            results['dataset_name'], results['class_names']\n",
        "        )\n",
        "\n",
        "        # ROC криві для бінарної класифікації\n",
        "        if results['num_classes'] == 2:\n",
        "            roc_plot = plot_roc_curves(results['evaluation_results'])\n",
        "        else:\n",
        "            roc_plot = None\n",
        "\n",
        "        # Межа прийняття рішень для 2D даних\n",
        "        if results['X_test'].shape[1] == 2:\n",
        "            decision_boundary_plot = plot_decision_boundary(\n",
        "                results['X_test'], results['y_test'],\n",
        "                results['keras_model'], results['sklearn_model'],\n",
        "                results['num_classes']\n",
        "            )\n",
        "        else:\n",
        "            decision_boundary_plot = None\n",
        "\n",
        "        # Формуємо список графіків для виведення\n",
        "        output_plots = [learning_curve_plot, metrics_plot, cm_plot, misclassifications_plot]\n",
        "\n",
        "        if roc_plot is not None:\n",
        "            output_plots.append(roc_plot)\n",
        "\n",
        "        if decision_boundary_plot is not None:\n",
        "            output_plots.append(decision_boundary_plot)\n",
        "\n",
        "        # Повертаємо результати\n",
        "        return [output_text] + output_plots + [None] * (6 - len(output_plots))\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"Помилка при навчанні моделей: {str(e)}\"\n",
        "        # Повертаємо помилку та порожні графіки\n",
        "        return [error_message] + [None] * 6"
      ],
      "metadata": {
        "id": "9WBJKB7-Kb4e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Створення Gradio інтерфейсу\n",
        "with gr.Blocks(title=\"Нейронні мережі для задач класифікації\") as demo:\n",
        "    gr.Markdown(\"# Нейронні мережі для задач класифікації\")\n",
        "    gr.Markdown(\"У цьому інтерфейсі ви можете експериментувати з різними архітектурами нейронних мереж та порівнювати їх з класичними методами машинного навчання\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            # Вибір набору даних\n",
        "            variant = gr.Dropdown(\n",
        "                choices=[\n",
        "                    (f\"Варіант {i}: {name}\", i) for i, name in enumerate([\n",
        "                        \"Breast Cancer Wisconsin\",\n",
        "                        \"Fashion MNIST\",\n",
        "                        \"Pima Indians Diabetes\",\n",
        "                        \"Wine Quality\",\n",
        "                        \"Wine Dataset\",\n",
        "                        \"Titanic\",\n",
        "                        \"Heart Disease\",\n",
        "                        \"Iris\",\n",
        "                        \"Mushroom Dataset\",\n",
        "                        \"MNIST Digits\"\n",
        "                    ], 1)\n",
        "                ],\n",
        "                value=1,\n",
        "                label=\"Варіант набору даних\"\n",
        "            )\n",
        "\n",
        "            test_size = gr.Slider(\n",
        "                minimum=10,\n",
        "                maximum=50,\n",
        "                value=20,\n",
        "                step=5,\n",
        "                label=\"Розмір тестової вибірки (%)\"\n",
        "            )\n",
        "\n",
        "            random_state = gr.Slider(\n",
        "                minimum=0,\n",
        "                maximum=100,\n",
        "                value=42,\n",
        "                step=1,\n",
        "                label=\"Random State\"\n",
        "            )\n",
        "\n",
        "            with gr.Tab(\"Архітектура моделей\"):\n",
        "                keras_architecture = gr.Dropdown(\n",
        "                    choices=[\n",
        "                        (\"Проста\", \"simple\"),\n",
        "                        (\"Глибока\", \"deep\"),\n",
        "                        (\"Широка\", \"wider\"),\n",
        "                        (\"Згорткова (тільки для MNIST/Fashion)\", \"cnn\")\n",
        "                    ],\n",
        "                    value=\"simple\",\n",
        "                    label=\"Архітектура Keras моделі\"\n",
        "                )\n",
        "\n",
        "                sklearn_model_type = gr.Dropdown(\n",
        "                    choices=[\n",
        "                        (\"Багатошаровий перцептрон\", \"mlp\"),\n",
        "                        (\"Логістична регресія\", \"logistic\")\n",
        "                    ],\n",
        "                    value=\"mlp\",\n",
        "                    label=\"Тип Scikit-learn моделі\"\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    first_layer_units = gr.Slider(\n",
        "                        minimum=4,\n",
        "                        maximum=128,\n",
        "                        value=32,\n",
        "                        step=4,\n",
        "                        label=\"Нейрони в першому шарі\"\n",
        "                    )\n",
        "\n",
        "                    second_layer_units = gr.Slider(\n",
        "                        minimum=2,\n",
        "                        maximum=64,\n",
        "                        value=16,\n",
        "                        step=2,\n",
        "                        label=\"Нейрони в другому шарі\"\n",
        "                    )\n",
        "\n",
        "                activation = gr.Dropdown(\n",
        "                    choices=[\n",
        "                        (\"ReLU\", \"relu\"),\n",
        "                        (\"Sigmoid\", \"sigmoid\"),\n",
        "                        (\"Tanh\", \"tanh\")\n",
        "                    ],\n",
        "                    value=\"relu\",\n",
        "                    label=\"Функція активації\"\n",
        "                )\n",
        "\n",
        "                dropout_rate = gr.Slider(\n",
        "                    minimum=0.0,\n",
        "                    maximum=0.5,\n",
        "                    value=0.2,\n",
        "                    step=0.05,\n",
        "                    label=\"Dropout Rate\"\n",
        "                )\n",
        "\n",
        "            with gr.Tab(\"Параметри навчання\"):\n",
        "                with gr.Row():\n",
        "                    optimizer = gr.Dropdown(\n",
        "                        choices=[\n",
        "                            (\"Adam\", \"adam\"),\n",
        "                            (\"SGD\", \"sgd\"),\n",
        "                            (\"RMSprop\", \"rmsprop\")\n",
        "                        ],\n",
        "                        value=\"adam\",\n",
        "                        label=\"Оптимізатор (Keras)\"\n",
        "                    )\n",
        "\n",
        "                    learning_rate = gr.Slider(\n",
        "                        minimum=0.0001,\n",
        "                        maximum=0.01,\n",
        "                        value=0.001,\n",
        "                        step=0.0001,\n",
        "                        label=\"Швидкість навчання\"\n",
        "                    )\n",
        "\n",
        "                with gr.Row():\n",
        "                    batch_size = gr.Dropdown(\n",
        "                        choices=[8, 16, 32, 64, 128],\n",
        "                        value=32,\n",
        "                        label=\"Розмір батчу (Keras)\"\n",
        "                    )\n",
        "\n",
        "                    epochs = gr.Slider(\n",
        "                        minimum=10,\n",
        "                        maximum=200,\n",
        "                        value=50,\n",
        "                        step=10,\n",
        "                        label=\"Максимальна кількість епох (Keras)\"\n",
        "                    )\n",
        "\n",
        "                with gr.Row():\n",
        "                    alpha = gr.Slider(\n",
        "                        minimum=0.0001,\n",
        "                        maximum=0.1,\n",
        "                        value=0.0001,\n",
        "                        step=0.0001,\n",
        "                        label=\"Alpha (регуляризація)\"\n",
        "                    )\n",
        "\n",
        "                    max_iter = gr.Slider(\n",
        "                        minimum=100,\n",
        "                        maximum=1000,\n",
        "                        value=200,\n",
        "                        step=50,\n",
        "                        label=\"Максимальна кількість ітерацій (Scikit-learn)\"\n",
        "                    )\n",
        "\n",
        "            submit_btn = gr.Button(\"Навчити та оцінити моделі\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            output_text = gr.Markdown(label=\"Результати\")\n",
        "\n",
        "            with gr.Tab(\"Навчання\"):\n",
        "                learning_curve_plot = gr.Plot(label=\"Криві навчання (Keras)\")\n",
        "\n",
        "            with gr.Tab(\"Метрики\"):\n",
        "                metrics_plot = gr.Plot(label=\"Порівняння метрик моделей\")\n",
        "\n",
        "            with gr.Tab(\"Матриці помилок\"):\n",
        "                cm_plot = gr.Plot(label=\"Матриці помилок\")\n",
        "\n",
        "            with gr.Tab(\"Неправильно класифіковані зразки\"):\n",
        "                misclassifications_plot = gr.Plot(label=\"Приклади помилкової класифікації\")\n",
        "\n",
        "            with gr.Tab(\"ROC криві\"):\n",
        "                roc_plot = gr.Plot(label=\"ROC криві (тільки для бінарної класифікації)\")\n",
        "\n",
        "            with gr.Tab(\"Межі прийняття рішень\"):\n",
        "                decision_boundary_plot = gr.Plot(label=\"Межі прийняття рішень (тільки для 2D даних)\")\n",
        "\n",
        "    # Підключення функції до кнопки\n",
        "    submit_btn.click(\n",
        "        fn=gradio_interface,\n",
        "        inputs=[variant, test_size, keras_architecture, sklearn_model_type,\n",
        "               first_layer_units, second_layer_units, activation, learning_rate,\n",
        "               optimizer, batch_size, epochs, dropout_rate, alpha, max_iter, random_state],\n",
        "        outputs=[output_text, learning_curve_plot, metrics_plot, cm_plot,\n",
        "                misclassifications_plot, roc_plot, decision_boundary_plot]\n",
        "    )\n",
        "\n",
        "# Запуск інтерфейсу\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "QcHO2jcrEJrg",
        "outputId": "e1093786-1d5f-4d7e-b4b2-d43ddcb20f5c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6261d2cf9fb6acd6fa.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6261d2cf9fb6acd6fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        "###Завдання 7.  Документування та висновки\n",
        "- Опишіть методологію і отримані результати\n",
        "- Порівняйте різні підходи та зробіть висновки\n",
        "- Запропонуйте можливі покращення"
      ],
      "metadata": {
        "id": "eFpNOlqfmrVH"
      }
    }
  ]
}